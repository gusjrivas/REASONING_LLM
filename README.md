# REASONING_LLM

# Proyecto Procesamiento del Lenguaje Natural 2 (FIUBA): LLM con Cadena de Pensamiento Simulada para Resoluci√≥n de Problemas Complejos

**Curso:** Procesamiento del Lenguaje Natural 2
**Instituci√≥n:** Facultad de Ingenier√≠a, Universidad de Buenos Aires (FIUBA)
**Autor/a:** Gustavo Juli√°n Rivas
**Fecha:** 25 de abril de 2025

---

## 1. Resumen del Proyecto

Este proyecto consiste en una Prueba de Concepto (PoC) que explora la implementaci√≥n de una **cadena de pensamiento (Chain of Thought - CoT)** simulada utilizando un Modelo de Lenguaje Grande (LLM) para abordar la resoluci√≥n de problemas complejos que requieren m√∫ltiples pasos l√≥gicos o de c√°lculo.

El sistema recibe una pregunta compleja en lenguaje natural, la descompone en sub-tareas, ejecuta cada una de ellas secuencialmente (utilizando el LLM para el razonamiento y c√°lculo intermedio), y finalmente sintetiza una respuesta final. La aplicaci√≥n, desarrollada con Streamlit, visualiza din√°micamente este proceso paso a paso, ofreciendo transparencia sobre el "razonamiento" simulado del modelo. Adicionalmente, se realiza un seguimiento del consumo de tokens y se estima el costo asociado al uso de la API de OpenAI.

## 2. Objetivos

*   Implementar un marco de trabajo para simular una cadena de pensamiento (CoT) utilizando llamadas secuenciales a un LLM (GPT-4o).
*   Demostrar la capacidad de un LLM para descomponer un problema complejo en sub-tareas manejables (planificaci√≥n).
*   Evaluar la habilidad del LLM para ejecutar pasos de c√°lculo intermedios siguiendo instrucciones precisas y utilizando contexto de pasos anteriores.
*   Desarrollar un "agente" sintetizador (basado en LLM) capaz de consolidar resultados parciales en una respuesta final coherente y formateada.
*   Proporcionar una interfaz de usuario interactiva (Streamlit) que visualice el proceso de razonamiento paso a paso.
*   Cuantificar el uso de recursos computacionales (tokens) y estimar el costo asociado a este enfoque de razonamiento simulado.

## 3. Metodolog√≠a y Enfoque T√©cnico

La soluci√≥n se basa en un **enfoque de agentes simulados**, donde diferentes instancias de llamadas al LLM, guiadas por prompts espec√≠ficos (ingenier√≠a de prompts), desempe√±an roles distintos dentro de un flujo orquestado:

1.  **Agente Descompositor:** Recibe la pregunta compleja inicial y genera un plan detallado, numerado y secuencial, indicando las operaciones y variables clave para cada paso.
2.  **Agente Verificador del Plan:** Eval√∫a la l√≥gica, completitud y correcci√≥n del plan generado por el descomponitor.
3.  **Agente Solucionador:** Ejecuta cada paso individual del plan. Recibe la descripci√≥n del paso actual y el contexto acumulado (pregunta original, plan, resultados de pasos anteriores). Se le instruye expl√≠citamente para mostrar su trabajo de c√°lculo y mantener alta precisi√≥n. *En esta implementaci√≥n, el LLM realiza los c√°lculos intermedios.*
4.  **Agente Sintetizador (Auditor Final):** Recibe la pregunta original, el plan y todos los resultados parciales detallados. Su funci√≥n es extraer la informaci√≥n relevante, realizar los c√°lculos finales (ej. aplicaci√≥n de descuentos, redondeo) y formatear la respuesta final de acuerdo a los requerimientos expl√≠citos de la pregunta original.

Este flujo secuencial simula una cadena de pensamiento, donde la salida de una etapa alimenta la siguiente. La interfaz de Streamlit se actualiza despu√©s de cada etapa para reflejar el progreso.

## 4. Arquitectura y Tecnolog√≠as

*   **Lenguaje:** Python 3.x
*   **Interfaz de Usuario:** Streamlit (`streamlit`)
*   **Modelo de Lenguaje:** OpenAI GPT-4o (accedido v√≠a API)
*   **Cliente API:** Biblioteca oficial `openai`
*   **Bibliotecas Auxiliares:** `os`, `re`, `json`, `traceback`, `math`

## 5. Recursos Adicionales

*   **Video Demostrativo:** Se incluye una breve demostraci√≥n en video del funcionamiento de la aplicaci√≥n en la carpeta `/video`.
*   **Casos de Prueba:** La carpeta `/test_cases` contiene el archivo `prompts_ejemplo.txt` con ejemplos de preguntas complejas utilizadas durante las pruebas y el desarrollo.

## 6. Requisitos Previos

*   Python (versi√≥n 3.9 o superior recomendada).
*   Acceso a internet.
*   Una clave API v√°lida de OpenAI.

## 7. Instalaci√≥n

1.  **Clonar o descargar el repositorio.**
2.  **Navegar al directorio del proyecto** en una terminal.
3.  **Crear un entorno virtual (recomendado):**
    ```bash
    python -m venv venv
    # Activar:
    #   Windows: venv\Scripts\activate
    #   macOS/Linux: source venv/bin/activate
    ```
4.  **Instalar las dependencias:**
    ```bash
    pip install -r requirements.txt
    ```
    *(Si `requirements.txt` no est√° presente, instalar manualmente):*
    ```bash
    pip install streamlit openai
    ```

## 8. Configuraci√≥n

*   **API Key de OpenAI:** Es **obligatorio** configurar su clave API de OpenAI como una variable de entorno llamada `OPENAI_API_KEY`.
    *   **Linux/macOS:** `export OPENAI_API_KEY="tu_sk-..."`
    *   **Windows (cmd):** `set OPENAI_API_KEY=tu_sk-...`
    *   **Windows (PowerShell):** `$env:OPENAI_API_KEY="tu_sk-..."`
    *   *(Aseg√∫rese de ejecutar el comando en la misma sesi√≥n de terminal donde ejecutar√° Streamlit, o config√∫rela de forma persistente en su sistema operativo).*

## 9. Ejecuci√≥n

1.  Aseg√∫rese de que el entorno virtual (si usa uno) est√© activado.
2.  Verifique que la variable de entorno `OPENAI_API_KEY` est√© definida.
3.  Desde el directorio ra√≠z del proyecto, ejecute:
    ```bash
    streamlit run reasoning_app.py
    ```
    *(Reemplace `reasoning_app.py` con el nombre real de su archivo principal si es diferente)*.
4.  La aplicaci√≥n se abrir√° en su navegador web predeterminado.

## 10. Uso de la Interfaz

1.  La aplicaci√≥n carga con una pregunta compleja de ejemplo en el √°rea de texto. Puede modificarla o ingresar una nueva.
2.  Presione el bot√≥n "**üöÄ Iniciar Razonamiento**".
3.  La interfaz mostrar√° un indicador de estado mientras el sistema procesa cada etapa (Descomposici√≥n, Verificaci√≥n, Soluci√≥n de Pasos, S√≠ntesis).
4.  La secci√≥n "**ü§î Cadena de Pensamiento**" se actualizar√° din√°micamente:
    *   Se mostrar√° el plan generado y su revisi√≥n.
    *   Los resultados detallados de cada paso aparecer√°n secuencialmente. Observe el formato matem√°tico renderizado.
5.  Una vez completado, se mostrar√° la "**‚úÖ Respuesta Final Sintetizada**".
6.  El reporte de "**üìä Tokens y Costo Estimado**" estar√° disponible al final.
7.  Utilice el bot√≥n "**üîÑ Nueva Consulta**" para limpiar los resultados y realizar otra prueba.

## 11. Limitaciones y Trabajo Futuro

*   **Precisi√≥n del LLM:** Aunque se usa GPT-4o y prompts detallados, la precisi√≥n de los c√°lculos intermedios realizados por el LLM no est√° 100% garantizada. Errores sutiles pueden ocurrir.
*   **Dependencia del Plan:** La calidad de la respuesta final depende fuertemente de la calidad del plan generado en la primera etapa. Un plan incorrecto o incompleto llevar√° a resultados err√≥neos.
*   **Manejo de Errores:** La detecci√≥n y recuperaci√≥n de errores es b√°sica. Un sistema m√°s robusto podr√≠a incluir reintentos o mecanismos de auto-correcci√≥n.
*   **Generalizaci√≥n:** Si bien el marco es gen√©rico, la efectividad para problemas muy diferentes al ejemplo depender√° de la capacidad del LLM para generar planes adecuados y ejecutar pasos variados.
*   **Optimizaci√≥n de Costos/Tokens:** El enfoque multi-llamada puede consumir una cantidad significativa de tokens.
*   **Trabajo Futuro:**
    *   Implementar el **Enfoque H√≠brido (Calculador Python):** Separar la ejecuci√≥n de c√°lculos matem√°ticos a c√≥digo Python para garantizar precisi√≥n absoluta, usando el LLM solo para planificaci√≥n y extracci√≥n de datos (como se discuti√≥ previamente).
    *   **Mecanismos de Re-planificaci√≥n:** Permitir que el sistema revise y corrija el plan si un paso falla o la revisi√≥n inicial es negativa.
    *   **Memoria/Estado M√°s Avanzado:** Incorporar memoria para manejar conversaciones o problemas que requieran recordar informaci√≥n a m√°s largo plazo.

---