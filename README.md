# REASONING_LLM

#  LLM con Cadena de Pensamiento Detallada (PoC)

Este proyecto es una Prueba de Concepto (PoC) desarrollada en el marco del Posgrado de IA de la FIUBA. Demuestra c贸mo un Modelo de Lenguaje Grande (LLM) como GPT-4o puede ser guiado para "razonar" paso a paso y resolver preguntas complejas, mostrando su proceso de pensamiento al usuario.

**El Problema:** Los LLMs a veces fallan en problemas que requieren m煤ltiples pasos de c谩lculo o l贸gica. 驴C贸mo podemos hacer que muestren su trabajo y mejorar su precisi贸n?

**La Soluci贸n:** Esta aplicaci贸n implementa una **cadena de pensamiento simulada**:

1.  **Descomposici贸n:** El LLM recibe la pregunta compleja y la divide en un plan de pasos l贸gicos.
2.  **Verificaci贸n (Opcional):** Otro llamado al LLM revisa si el plan es coherente.
3.  **Ejecuci贸n Paso a Paso:** El LLM ejecuta cada paso del plan, mostrando sus c谩lculos o an谩lisis intermedios. Usa el contexto de los pasos anteriores.
4.  **S铆ntesis Final:** Un 煤ltimo llamado al LLM revisa todos los resultados intermedios y genera la respuesta final, siguiendo el formato solicitado.

La interfaz, construida con **Streamlit**, muestra din谩micamente cada etapa del proceso, permitiendo al usuario ver c贸mo el LLM "piensa" para llegar a la soluci贸n. Adem谩s, calcula y muestra el uso de tokens y un costo estimado en USD para la ejecuci贸n.

## Tecnolog铆as

*   **Python**
*   **Streamlit:** Para la interfaz web interactiva.
*   **OpenAI API:** Para acceder a modelos como GPT-4o.
*   **Biblioteca `openai` de Python:** Para interactuar con la API.

## Requisitos Previos

*   Python 3.9 o superior.
*   Una clave API de OpenAI.

## Instalaci贸n

1.  **Clona el repositorio (si aplica) o guarda el c贸digo:** Guarda el c贸digo principal como `reasoning_app.py` (o el nombre que prefieras).
2.  **Crea un entorno virtual (recomendado):**
    ```bash
    python -m venv venv
    # Windows: venv\Scripts\activate
    # macOS/Linux: source venv/bin/activate
    ```
3.  **Instala las dependencias:**
    ```bash
    pip install streamlit openai
    ```

## Configuraci贸n

1.  **Configura tu API Key de OpenAI:** La forma m谩s segura es establecer una variable de entorno llamada `OPENAI_API_KEY` con tu clave secreta.
    *   **Linux/macOS:** `export OPENAI_API_KEY="tu_sk-..."`
    *   **Windows (cmd):** `set OPENAI_API_KEY=tu_sk-...`
    *   **Windows (PowerShell):** `$env:OPENAI_API_KEY="tu_sk-..."`

## C贸mo Ejecutar la Aplicaci贸n

1.  Abre tu terminal o l铆nea de comandos.
2.  Navega hasta el directorio donde guardaste el archivo `.py`.
3.  Aseg煤rate de que la variable de entorno `OPENAI_API_KEY` est茅 configurada en esa sesi贸n.
4.  Ejecuta el siguiente comando:
    ```bash
    streamlit run reasoning_app.py
    ```
    *(Reemplaza `reasoning_app.py` si guardaste el archivo con otro nombre)*.
5.  Se abrir谩 autom谩ticamente una pesta帽a en tu navegador web con la aplicaci贸n.

## C贸mo Usar la Interfaz

1.  Ver谩s un 谩rea de texto con una pregunta compleja de ejemplo (c谩lculo de construcci贸n). Puedes modificarla o escribir la tuya.
2.  Haz clic en el bot贸n "** Iniciar Razonamiento**".
3.  Observa la secci贸n "** Cadena de Pensamiento**":
    *   Aparecer谩 el plan generado por el LLM.
    *   Luego, los resultados de cada paso se ir谩n mostrando uno por uno a medida que el LLM los calcula.
    *   Finalmente, se mostrar谩 la respuesta final sintetizada.
    *   Podr谩s expandir la secci贸n "** Ver Reporte de Tokens y Costo Estimado**" para ver el detalle del uso de la API.
4.  Una vez terminado, puedes hacer clic en "** Nueva Consulta**" para limpiar los resultados y empezar de nuevo.

隆Explora c贸mo el LLM aborda diferentes problemas complejos!