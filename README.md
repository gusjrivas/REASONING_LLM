# REASONING_LLM

## Proyecto Procesamiento del Lenguaje Natural 2 (FIUBA): LLM con Cadena de Pensamiento Simulada para Resoluci칩n de Problemas Complejos

**Curso:** Procesamiento del Lenguaje Natural 2

**Instituci칩n:** Facultad de Ingenier칤a, Universidad de Buenos Aires (FIUBA)

**Autor:** Gustavo Juli치n Rivas

**Fecha:** 25 de abril de 2025

---

## 1. Resumen del Proyecto

Este proyecto consiste en una Prueba de Concepto (PoC) que explora la implementaci칩n de una **cadena de pensamiento (Chain of Thought - CoT)** simulada utilizando un Modelo de Lenguaje Grande (LLM) para abordar la resoluci칩n de problemas complejos que requieren m칰ltiples pasos l칩gicos o de c치lculo.

El sistema recibe una pregunta compleja en lenguaje natural, la descompone en sub-tareas, ejecuta cada una de ellas secuencialmente (utilizando el LLM para el razonamiento y c치lculo intermedio), y finalmente sintetiza una respuesta final. La aplicaci칩n, desarrollada con Streamlit, visualiza din치micamente este proceso paso a paso, ofreciendo transparencia sobre el "razonamiento" simulado del modelo. Adicionalmente, se realiza un seguimiento del consumo de tokens y se estima el costo asociado al uso de la API de OpenAI.

## 2. Objetivos

*   Implementar un marco de trabajo para simular una cadena de pensamiento (CoT) utilizando llamadas secuenciales a un LLM (GPT-4o).
*   Demostrar la capacidad de un LLM para descomponer un problema complejo en sub-tareas manejables (planificaci칩n).
*   Evaluar la habilidad del LLM para ejecutar pasos de c치lculo intermedios siguiendo instrucciones precisas y utilizando contexto de pasos anteriores.
*   Desarrollar un "agente" sintetizador (basado en LLM) capaz de consolidar resultados parciales en una respuesta final coherente y formateada.
*   Proporcionar una interfaz de usuario interactiva (Streamlit) que visualice el proceso de razonamiento paso a paso.
*   Cuantificar el uso de recursos computacionales (tokens) y estimar el costo asociado a este enfoque de razonamiento simulado.

## 3. Metodolog칤a y Enfoque T칠cnico

La soluci칩n se basa en un **enfoque de agentes simulados**, donde diferentes instancias de llamadas al LLM, guiadas por prompts espec칤ficos (ingenier칤a de prompts), desempe침an roles distintos dentro de un flujo orquestado:

1.  **Agente Descompositor:** Recibe la pregunta compleja inicial y genera un plan detallado, numerado y secuencial, indicando las operaciones y variables clave para cada paso.
2.  **Agente Verificador del Plan:** Eval칰a la l칩gica, completitud y correcci칩n del plan generado por el descomponitor.
3.  **Agente Solucionador:** Ejecuta cada paso individual del plan. Recibe la descripci칩n del paso actual y el contexto acumulado (pregunta original, plan, resultados de pasos anteriores). Se le instruye expl칤citamente para mostrar su trabajo de c치lculo y mantener alta precisi칩n. *En esta implementaci칩n, el LLM realiza los c치lculos intermedios.*
4.  **Agente Sintetizador (Auditor Final):** Recibe la pregunta original, el plan y todos los resultados parciales detallados. Su funci칩n es extraer la informaci칩n relevante, realizar los c치lculos finales (ej. aplicaci칩n de descuentos, redondeo) y formatear la respuesta final de acuerdo a los requerimientos expl칤citos de la pregunta original.

Este flujo secuencial simula una cadena de pensamiento, donde la salida de una etapa alimenta la siguiente. La interfaz de Streamlit se actualiza despu칠s de cada etapa para reflejar el progreso.

## 4. Arquitectura y Tecnolog칤as

*   **Lenguaje:** Python 3.x
*   **Interfaz de Usuario:** Streamlit (`streamlit`)
*   **Modelo de Lenguaje:** OpenAI GPT-4o (accedido v칤a API)
*   **Cliente API:** Biblioteca oficial `openai`
*   **Bibliotecas Auxiliares:** `os`, `re`, `json`, `traceback`, `math`

## 5. Recursos Adicionales

*   **Video Demostrativo:** Se incluye una breve demostraci칩n en video del funcionamiento de la aplicaci칩n en la carpeta `/video`.
*   **Casos de Prueba:** La carpeta `/test_cases` contiene el archivo `test_cases.txt` con ejemplos de preguntas complejas utilizadas durante las pruebas y el desarrollo.

## 6. Requisitos Previos

*   Python (versi칩n 3.9 o superior recomendada).
*   Acceso a internet.
*   Una clave API v치lida de OpenAI.

## 7. Instalaci칩n

1.  **Clonar o descargar el repositorio.**
2.  **Navegar al directorio del proyecto** en una terminal.
3.  **Crear un entorno virtual (recomendado):**
    ```bash
    python -m venv venv
    # Activar:
    #   Windows: venv\Scripts\activate
    #   macOS/Linux: source venv/bin/activate
    ```
4.  **Instalar las dependencias:**
    ```bash
    pip install -r requirements.txt
    ```
    *(Si `requirements.txt` no est치 presente, instalar manualmente):*
    ```bash
    pip install streamlit openai
    ```

## 8. Configuraci칩n

*   **API Key de OpenAI:** Es **obligatorio** configurar su clave API de OpenAI como una variable de entorno llamada `OPENAI_API_KEY`.
    *   **Linux/macOS:** `export OPENAI_API_KEY="tu_sk-..."`
    *   **Windows (cmd):** `set OPENAI_API_KEY=tu_sk-...`
    *   **Windows (PowerShell):** `$env:OPENAI_API_KEY="tu_sk-..."`
    *   *(Aseg칰rese de ejecutar el comando en la misma sesi칩n de terminal donde ejecutar치 Streamlit, o config칰rela de forma persistente en su sistema operativo).*

## 9. Ejecuci칩n

1.  Aseg칰rese de que el entorno virtual (si usa uno) est칠 activado.
2.  Verifique que la variable de entorno `OPENAI_API_KEY` est칠 definida.
3.  Desde el directorio ra칤z del proyecto, ejecute:
    ```bash
    streamlit run reasoning_app.py
    ```
    *(Reemplace `reasoning_app.py` con el nombre real de su archivo principal si es diferente)*.
4.  La aplicaci칩n se abrir치 en su navegador web predeterminado.

## 10. Uso de la Interfaz

1.  Ver치s un 치rea de texto con una pregunta compleja de ejemplo (c치lculo de construcci칩n). Puedes modificarla o escribir la tuya.
2.  Haz clic en el bot칩n "**游 Iniciar Razonamiento**".
3.  Observa la secci칩n "**游뱂 Cadena de Pensamiento**":
    *   Aparecer치 el plan generado por el LLM.
    *   Luego, los resultados de cada paso se ir치n mostrando uno por uno a medida que el LLM los calcula.
    *   Finalmente, se mostrar치 la respuesta final sintetizada.
    *   Podr치s expandir la secci칩n "**游늵 Ver Reporte de Tokens y Costo Estimado**" para ver el detalle del uso de la API.
4.  Una vez terminado, puedes hacer clic en "**游댃 Nueva Consulta**" para limpiar los resultados y empezar de nuevo.


